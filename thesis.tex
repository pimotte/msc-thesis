\documentclass[a4paper,11pt]{book}
%
% The current document is based on a document by Marten Wortel
% who is greatly acknowledged for making his document available
%
\usepackage{amsmath,amsthm,amsfonts,mathrsfs,anysize,fancyhdr,epsfig}

\newcommand{\bb}{\mathbb}
\newcommand{\mb}{\mathbf}
\newcommand{\mc}{\mathcal}
\newcommand{\pred}{\mathrm{Pred}}
\newcommand{\ov}{\overline}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem*{corollary}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{conjecture}{Conjecture}
\newtheorem*{example}{Example}
\newtheorem{algorithm}{Algorithm}


\begin{document}

\begin{titlepage}

\thispagestyle{empty}

{\hspace{10cm}
\begin{minipage}{5cm}
  \includegraphics{tudelft.eps}
\end{minipage}}

\begin{center}

\vspace{1.0cm}

\large
\textbf{\large{Delft University of Technology}} \\
\textbf{\large{Faculty of Electrical Engineering, Mathematics and Computer Science}} \\
\textbf{\large{Delft Institute of Applied Mathematics}}

\vspace{2.0cm}

\framebox[16cm]{\raisebox{0cm}[1.5cm][1.5cm]
 {\textbf{
   \begin{minipage}{13cm}\Large
   \begin{center}
       Considering temporal factors in distributed trust.
   \end{center}
   \end{minipage}}}}

\vspace{2.0cm}

\large A thesis submitted to the\\
Delft Institute of Applied Mathematics\\
in partial fulfillment of the requirements

\vspace{1.0cm}

for the degree\\

\vspace{1.0cm}

\textbf{\large{MASTER OF SCIENCE} \\
in \\
\large{APPLIED MATHEMATICS} \\
\vspace{1cm}
by}

\vspace{1cm}

\textbf{PIM OTTE}\\

\vspace*{\stretch{2}}

\textbf{Delft, the Netherlands \\
August 2016} \\

\vspace{1cm}

Copyright \copyright{} 2016 by Pim Otte. All rights reserved.
\end{center}

\end{titlepage}

\newpage

\thispagestyle{empty}

\quad

\newpage

\thispagestyle{empty}

\hspace{10cm}
\begin{minipage}{5cm}
  \includegraphics{tudelft.eps}
\end{minipage}

\begin{center}
\vspace*{\stretch{1}}

\textbf{\large{MSc THESIS APPLIED MATHEMATICS}}

\vspace{1.5cm}

\textbf{``Considering temporal factors in distributed trust''}

\vspace{1.5cm}

PIM OTTE\\

\vspace{1.5cm}

\textbf{\large{Delft University of Technology}}

\vspace{\stretch{5}}

\end{center}

\begin{center}
\begin{tabular}{ll}
\large{\bf{Daily supervisors}} & \large{\bf{Responsible professor}} \\
$\;$ & \\
\large{Dr.~D.~C.~Gijswijt}  & \large{Prof.\ dr.~ir.~K.~Aardal} \\
$\;$ & \\
\large{Dr.~J.~Pouwelse} & \phantom{niets} \\
\phantom{niets} & \phantom{niets} \\
$\;$ & \\
\large{\textbf{Other thesis committee members\qquad}} & \phantom{niets} \\
$\;$ & \\
\large{Drs.~F.~.I.Ctief } & \large{\dots} \\
$\;$ & \\
\large{\dots} & \large{\dots} \\
$\;$ & \\
\phantom{niets} & \phantom{niets} \\
$\;$ & \\
\large{August 2016} & \large{Delft, the Netherlands}
\end{tabular}
\end{center}
\newpage

\thispagestyle{empty}

\quad

\newpage


\chapter*{\centering \begin{normalsize}Abstract\end{normalsize}}

In this thesis, the problem of estimating trust in a distributed network is considered.

\clearpage
\tableofcontents
\pagenumbering{arabic}
\chapter{Introduction}
    
%Insert general gewauwel here

The internet is more distributed than ever [citation needed].

Distributed systems suffer from a tragedy of the commons.

Defending against sybils is interesting in the sense
that it will also imply that there is no gross unfairness in the system.


\section{Base model}

Traditionally, sybil defense mechanisms are built to exploit some graph,
either based in external trust or interactions. In the case of interactions,
information over time is summarized in a single number. However, this loses
a lot of relevant information.

In order to incorporate temporal information in sybil defense mechanisms,
there will be some assumptions needed about the information which is available.
Hence, applications which fit the following model will be explored.

\begin{definition}[Ordered interaction model]
    An \emph{ordered interaction model} $M$ consists of two sets:  
    
    \begin{itemize}
        \item $P$, a finite set of participants
        \item $I$, a finite partially ordered set of interactions
    \end{itemize}

    Participants represent entities that can interact with each other.
    An interaction consists of two participants, one or both performing
    work for each other. 
    
    An interaction is defined by two pairs of properties:
    \begin{enumerate}
        \item $p, q \in P$, two participants involved in the interaction.
        \item $w_p, w_q \in \bb{R}_{\geq0}$, representing amount of work done by $p$, respectively $q$.
    \end{enumerate}

    Furthermore, for each $p \in P$, the partial order on $I$ must induce a total order on 
    \begin{equation*}
        I_p = \{i \in I : p \mbox{ is a participant in } i\}
    \end{equation*}
\end{definition}

Note that because of the total order on the finite set $I_p$, the following holds:
For each $i \in I_p$, either $i$ is the minimum of $I_p$, or there exists
a unique $i' \in I_p$ such that $i' < i$, and no $i'' \in I_p$ exists such that
$i' < i'' < i$. We define: $\pred(p, i) := i'$, so interaction $i'$ is the predecessor
of interaction $i$ for participant $p$.

  
This model induces a graph that resembles traditional interaction graphs, but preserves the knowledge
of the order of interactions.
\begin{definition}[Ordered interaction graph]
    The directed graph $G_M = (V, A)$ is defined as the \emph{ordered interaction graph} derived from an ordered interaction model $M = (P,I)$.
    Its structure is as follows:

    \begin{itemize}
        \item $V := \{ v_{i} : i \in I\}$\\
        \item $A := \{ (v_{i}, v_{j}) : i, j \in I, \mbox{ s.t. } \exists p \in P, \mbox{ where } i = \pred(p, j)\}$
    \end{itemize}

    In contexts where not defined otherwise, the weight of an arc is the amount of the work performed by $p$ in
    interaction $i$. 
\end{definition}

\subsection{Timeline inference for the base model}

With OIMs, the ordering information of interactions is largely preserved. However, for some
applications it will be useful to be able to associate timestamps with interactions. To
this point, we introduce the concept of timeline inference.

\begin{definition}[Timeline inference for ordered interaction models]
    Let $M = (P, I)$ be an ordered interaction model. 

    $f$ is a \emph{timeline information function} if:
    \begin{itemize}
        \item $J \subseteq I$ 
        \item $f : J \to \bb{R}$
        \item $f$ is increasing with respect to the partial ordering on $I$. That is:
            for $i,j \in J$, if $i \leq j$, then $f(i) \leq f(j)$. 
    \end{itemize}

    By $f[J]$ we denote the range of $f$.
    This allows to define the timeline inference function $T_f$:

    \begin{itemize}
        \item $T_f : I \to f[J] \times f[J]$
        \item $T_f(i) := (\max \{f(j): j \in I, j \leq i\}, \min \{f(j) : j \in I, i \geq j\})$
    \end{itemize}
    
    In addition, we define $\ov{T_f} : I \to \bb{R}$ by $\ov{T_f}(i)$ being the average of the
    two values $T_f(i)$.
\end{definition}


If $f$ represents some sort of temporal information about the interactions in $J$, 
then the timeline inference function gives interval of minimal size containing valid choices for extrapolating
$f$ beyond elements in $J$. In adddition, for every $j \in J$, $T_f(j) = (f(j), f(j))$.

\section{Time-discounted interaction effort}

In order to model the effort needed to interact, we consider the fact that commitment to
a system takes some effort. To this end, we introduce the concept of time-discounted effort.

\begin{definition}[Time-discounted effort]
    Let $M = (P, I)$ be an ordered interaction model, let $f$ be a timeline information function.
    Let $d: \bb{R} \to \bb{R}^+$ be a decreasing function. The time-discounted interaction
    effort is defined as:
    \begin{align*}
        e: & P \times I \to \bb{R} \\
        e(p, i) &= w_p(i)*d(\ov{T_f}(i)) \\
    \end{align*}
\end{definition}

This definition implies that an interaction in the past is regarded as having taken more effort.



\section{Base model applied to Tribler}

To obtain more insight into the ordered interaction model, consider the following application:

Tribler is an anonymous peer-to-peer file sharing client. In the application of the model,
the set of participants consists of Tribler clients. Each Tribler client is uniquely identifiable,
but a single real world entity could have multiple participants. In Tribler an interaction
consists of two participants uploading data to each other. The amount of work $w_p$ performed
by a participant $p$ is the amount of megabytes uploaded to their peer ($q$), in MB.

In Tribler, these interactions are recorded in a distributed datastructure, called the multichain.
Every client saves and signs their interactions, marked with a sequence number. They will then request
a digital signature from their peer, who will mark the interaction with their own sequence number.
These sequence numbers induce a partial ordering, where $i < j$, if and only if there exists
a sequence $(i_0, i_1, \ldots i_n)$, where $i=i_0, j=i_n$ and every pair $(i_k, i_{k+1})$ has
a common participant, for which the sequence number in $i_k$ is lower than in $i_{k+1}$.
This results in a full order on $I_p$, since in that case $(i, j)$ is a valid sequence if
$i$ occurred before $j$ and both involve participant $p$.

In Tribler, timeline information inference can be done by each participant $p$, if they
keep a local record of the time at which they participated in interaction $i$. In this
case the timeline information function will be $f : I_p \to \bb{R}$, where $f(i)$ is
the timestamp of interaction $i$.



\section{The resource distribution problem}

Consider an ordered interaction model $M$. At a specific moment in time, a participant
$p$ has a certain set of other participants suitable for interaction. The problem
at hand is: How should $p$ choose distribute their resources to do work for other participants?


To answer this question, there are several aspects to consider. Firstly, is the issue of
what $p$ intends to achieve. Does $p$ want to distribute their resources in a way that
best helps the collective of all participants? Or maybe he intends to do it such that
he performs work for the people who are most likely to return the favour. Another possibility
is that he wants to compensate others for work they performed for him previously.
Some of these possibilities touch on the game theoretic and sociopsychological angles to this problem.

The second aspect is the availibility of information. In some ordered interaction models, $p$ may
have complete information considering all interactions. In other settings, in particular distributed
systems, it may be expensive or time consuming to obtain all information. It could be that $p$ has only
information concerning their own interactions, or they can just obtain a limited number of transactions.

The third aspect is that there could be additional issues that are not captured in the ordered interaction
model. In particular, the truthfulness of interactions, behavior of participants outside of
events in this framework 


\chapter{Possibility of sybil-proofness}

We consider the model of accounting mechanisms as presented by Seuken et al. \cite{seuken2014sybil}.

In this model, it has been shown that no mechanism exists that is independent of the number of disconnected
agents, is symmetric (or: anonymous) that satisfies long-term misreport-proofness, 
satisfies weak transitive trust and is robust against weakly benificial sybil attacks. 

Of these five properties, any system built on top of the multichain would not need to satisfy misreport-proofness.
Reports in the multichain can only be made with consent of both parties and reports between sybils are part
of the model of a sybil attack. This fact shifts the problem of misreporting to obtaining consent during
the interaction. This method has several practical issues, but these are much easier to resolve than
the problems that arise when this needs to be sorted out in hindsight, in particular because
it results in mechanisms like Drop-Edge, where the most relevant information has to be disregarded,
because it's not feasible to disseminate conflicting reports that ultimately result in a ``he-said-she-said''
situation.

The original BarterCast mechanism computed the trust participant $i$ has in participant $j$ by considering
the graph of all participants, with directed edges from one participant to another, where the capacities
are determined by the magnitude of the uploads. The trust $i$ has in $j$ is then a monotonic function
of the difference of the flow from $i$ to $j$ and the flow from $j$ to $i$. 

This mechanism suffers from 2 problems:

\begin{enumerate}
    \item It is extremely vulnerable to misreporting attacks
    \item Trusting someone if they have transitively uploaded more makes sense. In the download direction, not so much.
\end{enumerate}


The multichain solves the first problem. The second problem seems philosophical at first, but there is an actual sybil
attack that exploits this property:

Let $i, j$ be participants. Let $j$ upload 1MB to $i$. Hence, the flow from $j$ to $i$ is 1, the flow
from $i$ to $j$ is 0. Let $j$ create a sybil, $s_1$ and claim that $s_1$ uploaded 1MB to $j$.
Now the flow from $i$ to $s_1$ is $0$, the flow from $s_1$ to $i$ is 1. Now $s_1$ asks
for data from $i$, and $i$ obliges and uploads 1MB. Now the flow between $i$ and the others is
1 in either direction. Now let $j$ create another sybil $s_2$ and claim it uploaded 1MB
to $j$. Now the flow from $i$ to $s_2$ is 0, but the flow from $s_2$ to $i$ is 1. So when
$s_2$ asks for data, $i$ is likely to oblige.

This leads to the search for a better mechanism. Before moving on to an actual mechanism, the model
by Seuken and Parkes will be considered and expanded upon. 

\begin{definition}[Colluding sybil attack]
    Given a subjective work graph $G_i = (V_i, E_i, w_i)$.
    A sybil atttack by agents $J \subseteq V_i$ is a tuple $\sigma_J = (V_s, E_s, w_s)$
    where $V_s = \{ s_{J_1}, s_{J_2}, \ldots\}$ is a set of sybils, 
    $E_s = \{(x, y) : x, y \in S \cup J\}$, and $w_s$ are the edge weights for
    the edges in $E_s$. Applying the sybil attack to agent $i$'s subjective work graph
    is done in the same way as for normal sybil attacks.
    \label{def:collsybil}
\end{definition}

On the face, Definition \ref{def:collsybil} doesn't seem to add much to the definition of a sybil attack.
After all, an attacker can already create an arbitrary amount of identities. However, the definition of a
sybil attack only allows a single point where sybils can interact with the rest network, which is a pretty limited
view of possible attacks. 

\begin{definition}[Sybil attack profit]
    Let $G_i$ be a subjective work graph. For all $j \in \bb{N}$, let $(\sigma_J)_j$ be a sybil attack
    on $(G_i)_j$, where $(G_i)_0 := G_i$ and $(G_i)_j$ for $j > 0$ is defined by the subjective
    work graph that consists of $(G_i)_{j-1}$ and the assignment of one unit of work to 
    $A(S^M( (G_i)_{j-1}, C_i))$.

    Let $\omega^n_-$ be the amount of work that any of the participants in $J$ have performed for
    the network after $n$ steps. Let $\omega^n_+$ be the amount of work that $J$ of any of their
    sybils obtain from the network.

    The profit of this sequence of sybil attacks is:
    \begin{equation*}
        \sup \{\frac{\omega^n_+}{\omega^n_-}\ : n \in \bb{N}, \omega^n_- \neq 0\}
    \end{equation*}

    If this supremum is unbounded, the sybil attack is strongly beneficial.

    If the supremum exists and is strictly larger than 1, the sybil attack is 
    profitably weakly benificial.

    If the supremum exists and is smaller than or equal to 1, the sybil attack
    is unprofitably weakly benificial. This case is also known as ``contributing to the network''.
\end{definition}

\begin{definition}[Net-flow limited contribution]
    The Net-flow limited contribution accounting mechanism $M$ is defined as follows:
    Given a subjective work graph $G_i = (V_i, E_i, w_i)$ and choice set $C_i$, agent
    $i$ computes the the following for each agent $j$: 
    $c_j := \max\{MF_{G_i}(j,i) - MF_{G_i}(i,j), 0\}$.
    Let $G_i^N$ be the graph $G_i$ modified with $c_j$ as node capacities for each node,
    except for $c_i$ which should be unbounded.

    Now $S^M_j(G_i, C_i) = MF_{G_i^N}(j, i)$.
\end{definition}

\begin{theorem}[Properties and robustness of Net-flow]
    Net-flow satisfies IDA, ANON, weak transitive trust and is robust against
    weakly-benificial sybil attacks.

    \label{thm:prop-rob-net-flow}
\end{theorem}

\begin{proof}
    IDA follows from the fact that flow to and from agents does not change if independent agents
    are added or removed. ANON follows from the fact that relabelling nodes will not change the flows.

    Let $k$ be the node added and let 
    $M := \max_{j \in C_i}\{S^M_j(G_i, C_i)\}$ be the largest amount of reputation in the system.
    Then using $W_j = M+1$ and $W_k = M+1$ satisfies the requirements of weak transitive trust.

    Since sybils only have connections to $j$, they cannot be involved in the flow to $j$, hence
    $M$ is resistant to sybil attacks of type $(1)$. For the same reason this scheme is resiliant
    to attack of type (2). For case (3), $s$ can only consume at most the net-flow of $j$ ($c_j$)
    units of work, at which point the net-flow and the reputation of $j$ will be $0$. The net-flow
    is bounded by the contribution of $j$ to the network, so it is impossible to turn a profit of this.
\end{proof}


Couple of notes:
\begin{enumerate}
    \item This mechanism is choice-set independent, which means that computation can be cached.
    \item The definition of weak sybil attacks doesn't actually include information about the leverage factor.
    \item Scaling the net-flow can actually give more trust at the cost of less sybil-resistance.
\end{enumerate}

Weak spots in the attack model:
\begin{enumerate}
    \item The only sybil structures considered are ``simple'' sybil structures (1 main guy, with sybils only connected
        to him)
    \item The sybil attacks just consider increase and decrease of scores and don't specify the utility of an attack
\end{enumerate}

\subsection{Unbounded accounting mechanisms are never sybil-proof}

\begin{definition}[Unbounded accounting mechanism]
    An accounting mechanism $M$ is unbounded, if for any sequence of
\end{definition}


\chapter{Research questions}

For various reasons, distributed systems can have advantages over traditional centralized
systems. However, distributing a system comes with several challenges, in particular that
the participants in this system will need to contribute in order for the system to
function. This can easily lead to a tragedy of the commons, where everyone is slacking,
but the result would be better if everyone pitched in a small amount of effort.

The focus of this thesis is the following question:

\begin{center}
    Can participants in a distributed network use information about the order of
    interactions to fairly distribute resources?
\end{center}

To determine how to distribute resources, we consider accounting mechanisms. Accounting
mechanisms can be used to assign a score to participants. These scores can then
be used to determine priority in resource distribution.

To restrict the scope of this research, only accounting mechanism are considered as a method
of using the information about the order of interactions. This reduces the main research question
to the following:

Does information about the order of interactions allow the design of an accounting mechanism
that satisfies the following three properties?

\begin{itemize}
    \item The accounting mechanism is fair. That is, the accounting mechanism result in
        similar priorities to some objective measure of contribution.
    \item The accounting mechanism is manipulation-resistant. That is, participants 
        cannot profit by methods other than actual contributions.
    \item The accounting mechanism is efficiently computable, either by the system as a whole,
        or by each participant.
\end{itemize}




\bibliography{thesis}{}
\bibliographystyle{plain}



\chapter{A short history of reputation systems in Tribler}

The first reputation system that was introduced in Tribler was BarterCast \cite{meulpolder2009bartercast}.
BarterCast is a system designed to deter what is described as ``lazy freeriders''.
In this paper, Meulpolder et al. suggest that for most practical applications, a reputation system does not
need to account for malicious users, just for lazy users. This assertion is based in the observation
that users classified as ``die-hard freeriders'', people who resort to using non-standard software to
cheat the system, are relatively uncommon in real-world systems. 

BarterCast is built on voluntary reporting. All participants in the system can report to other participants
about their interactions with third parties. These reports contain information about how much data
was exchanged between the two participants. These reports are then used in a max-flow based algorithm.
The graph that is constructed has all participants as nodes. Edges are directed and and the capacity
of an edge from participant $i$ to participant $j$ is equal to the magnitude of all data that $i$ has
uploaded to $j$ in bytes. Using this graph, the subjective reputation of $j$ from the perspective
of $i$ is the result of a monotonous function applied to the difference of the max-flow from $j$ to $i$
minus the max-flow from $i$ to $j$.

BarterCast has various desirable properties. Firstly, participants contributing more resources, or consuming
less resources, have a higher reputation. Secondly, it captures the concept of transitive trust. If participant
$j$ uploads a lot of data to participant $i$, $i$ will consider participants who help $j$ reputable. Thirdly,
it is more resistant to cheaters than systems that are based on participants self-reporting their own uploads and
downloads. Finally, this is a system that does not require the presence of any centrality. 

However, BarterCast also has some flaws. In particular, there is a disincentive for participants to report
interactions in which they had a net negative contribution to the network. Even worse, there is no mechanism
to verify who is lying in the case of conflicting reports. This means there exists a strictly optimal 
reporting strategy: Claiming that you uploaded a lot of data to one or more people, even if that is not
the case. This is a major weakness in the protocol and a solution has been suggested by Seuken and 
Parkes~\cite{seuken2010accounting}.

In this paper, Seuken and Parkes introduce the concept of an accounting mechanism. This formalization gives
a little bit more structure to the problem at hand. It is here that the notions of subjective work graphs
and choice sets are also formalized. Subjective work graphs allow for a framework in which participants
do not have a full view of the network, but only have information about participants that they have interacted
with and their peers. Choice sets provide a mechanism to describe which set of participants are requesting
service from another participant at a fixed point in time. This concept is relevant, because the way
Seuken and Parkes suggest to patch the problem with BarterCast is to simply ignore all reports of participants
in the choice set and then compute the BarterCast score from the resultant graph.
This solves a large part of the reporting problem. Since there is no longer a disincentive
to report correctly, the assumption is that participants will cooperate and provide reports. It also provides
the 

\end{document}

