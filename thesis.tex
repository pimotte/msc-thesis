\documentclass[a4paper,11pt]{book}
%
% The current document is based on a document by Marten Wortel
% who is greatly acknowledged for making his document available
%
\usepackage{amsmath,amsthm,amsfonts,mathrsfs,anysize,fancyhdr,epsfig}

\newcommand{\bb}{\mathbb}
\newcommand{\mb}{\mathbf} \newcommand{\mc}{\mathcal}
\newcommand{\pred}{\mathrm{Pred}}
\newcommand{\ov}{\overline}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{property}{Property}
\newtheorem{lemma}{Lemma}
\newtheorem*{corollary}{Corollary}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{conjecture}{Conjecture}
\newtheorem*{example}{Example}
\newtheorem{algorithm}{Algorithm}


\begin{document}

\begin{titlepage}

\thispagestyle{empty}

{\hspace{10cm}
\begin{minipage}{5cm}
  \includegraphics{tudelft.eps}
\end{minipage}}

\begin{center}

\vspace{1.0cm}

\large
\textbf{\large{Delft University of Technology}} \\
\textbf{\large{Faculty of Electrical Engineering, Mathematics and Computer Science}} \\
\textbf{\large{Delft Institute of Applied Mathematics}}

\vspace{2.0cm}

\framebox[16cm]{\raisebox{0cm}[1.5cm][1.5cm]
 {\textbf{
   \begin{minipage}{13cm}\Large
   \begin{center}
       Considering temporal factors in distributed trust.
   \end{center}
   \end{minipage}}}}

\vspace{2.0cm}

\large A thesis submitted to the\\
Delft Institute of Applied Mathematics\\
in partial fulfillment of the requirements

\vspace{1.0cm}

for the degree\\

\vspace{1.0cm}

\textbf{\large{MASTER OF SCIENCE} \\
in \\
\large{APPLIED MATHEMATICS} \\
\vspace{1cm}
by}

\vspace{1cm}

\textbf{PIM OTTE}\\

\vspace*{\stretch{2}}

\textbf{Delft, the Netherlands \\
August 2016} \\

\vspace{1cm}

Copyright \copyright{} 2016 by Pim Otte. All rights reserved.
\end{center}

\end{titlepage}

\newpage

\thispagestyle{empty}

\quad

\newpage

\thispagestyle{empty}

\hspace{10cm}
\begin{minipage}{5cm}
  \includegraphics{tudelft.eps}
\end{minipage}

\begin{center}
\vspace*{\stretch{1}}

\textbf{\large{MSc THESIS APPLIED MATHEMATICS}}

\vspace{1.5cm}

\textbf{``Considering temporal factors in distributed trust''}

\vspace{1.5cm}

PIM OTTE\\

\vspace{1.5cm}

\textbf{\large{Delft University of Technology}}

\vspace{\stretch{5}}

\end{center}

\begin{center}
\begin{tabular}{ll}
\large{\bf{Daily supervisors}} & \large{\bf{Responsible professor}} \\
$\;$ & \\
\large{Dr.~D.~C.~Gijswijt}  & \large{Prof.\ dr.~ir.~K.~Aardal} \\
$\;$ & \\
\large{Dr.~J.~Pouwelse} & \phantom{niets} \\
\phantom{niets} & \phantom{niets} \\
$\;$ & \\
\large{\textbf{Other thesis committee members\qquad}} & \phantom{niets} \\
$\;$ & \\
\large{Drs.~F.~.I.Ctief } & \large{\dots} \\
$\;$ & \\
\large{\dots} & \large{\dots} \\
$\;$ & \\
\phantom{niets} & \phantom{niets} \\
$\;$ & \\
\large{August 2016} & \large{Delft, the Netherlands}
\end{tabular}
\end{center}
\newpage

\thispagestyle{empty}

\quad

\newpage


\chapter*{\centering \begin{normalsize}Abstract\end{normalsize}}

In this thesis, the problem of estimating trust in a distributed network is considered.

\clearpage
\tableofcontents
\pagenumbering{arabic}
\chapter{Introduction}
    
%Insert general gewauwel here

The internet is more distributed than ever [citation needed].

Distributed systems suffer from a tragedy of the commons.

Defending against sybils is interesting in the sense
that it will also imply that there is no gross unfairness in the system.
\chapter{Research questions}

For various reasons, distributed systems can have advantages over traditional centralized
systems. However, distributing a system comes with several challenges, in particular that
the agents in this system will need to contribute in order for the system to
function. This can easily lead to a tragedy of the commons, where everyone is slacking,
but the result would be better if everyone pitched in a small amount of effort.

The focus of this thesis is the following question:

\begin{center}
    Can agents in a distributed network use information about the order of
    interactions to fairly distribute resources?
\end{center}

To determine how to distribute resources, we consider accounting mechanisms. Accounting
mechanisms can be used to assign a score to agents. These scores can then
be used to determine priority in resource distribution.

To restrict the scope of this research, only accounting mechanism are considered as a method
of using the information about the order of interactions. This reduces the main research question
to the following:

Does information about the order of interactions allow the design of an accounting mechanism
that satisfies the following three properties?

\begin{itemize}
    \item The accounting mechanism is fair. That is, the accounting mechanism result in
        similar priorities to some objective measure of contribution.
    \item The accounting mechanism is manipulation-resistant. That is, agents 
        cannot profit by methods other than actual contributions.
    \item The accounting mechanism is efficiently computable, either by the system as a whole,
        or by each agent.
\end{itemize}





\chapter{Multi-chain}

In order to exploit time-based information, this information will need to be
available in the first place. In order to allow general applicability of the
techniques, first the general model is considered, which is then shown to be
relevant in the particular case of the software known as ``Tribler''.


\section{Base model}

In order to incorporate temporal information in sybil defense mechanisms,
there will be some assumptions needed about the information which is available.
Hence, applications which fit the following model will be explored.

\begin{definition}[Ordered interaction model]
    An \emph{ordered interaction model} $M$ consists of two sets:  
    
    \begin{itemize}
        \item $P$, a finite set of agents
        \item $I$, a finite partially ordered set of interactions
    \end{itemize}

    agents represent entities that can interact with each other.
    An interaction consists of two agents, one or both performing
    work for each other. 
    
    An interaction is defined by two pairs of properties:
    \begin{enumerate}
        \item $p, q \in P$, two agents involved in the interaction.
        \item $w_p, w_q \in \bb{R}_{\geq0}$, representing amount of work done by $p$, respectively $q$.
    \end{enumerate}

    Furthermore, for each $p \in P$, the partial order on $I$ must induce a total order on 
    \begin{equation*}
        I_p = \{i \in I : p \mbox{ is an agent in } i\}
    \end{equation*}
\end{definition}

Note that because of the total order on the finite set $I_p$, the following holds:
For each $i \in I_p$, either $i$ is the minimum of $I_p$, or there exists
a unique $i' \in I_p$ such that $i' < i$, and no $i'' \in I_p$ exists such that
$i' < i'' < i$. We define: $\pred(p, i) := i'$, so interaction $i'$ is the predecessor
of interaction $i$ for agent $p$.

  
This model induces a graph that resembles traditional interaction graphs, but preserves the knowledge
of the order of interactions.
\begin{definition}[Ordered interaction graph]
    The directed graph $G_M = (V, A)$ is defined as the \emph{ordered interaction graph} derived from an ordered interaction model $M = (P,I)$.
    Its structure is as follows:

    \begin{itemize}
        \item $V := \{ v_{i} : i \in I\}$\\
        \item $A := \{ (v_{i}, v_{j}) : i, j \in I, \mbox{ s.t. } \exists p \in P, \mbox{ where } i = \pred(p, j)\}$
    \end{itemize}

    In contexts where not defined otherwise, the weight of an arc is the amount of the work performed by $p$ in
    interaction $i$. 
\end{definition}

\begin{definition}[Interaction graph]
    The (directed) interaction graph $G_M$ 
    %TODO fix shorthand

\end{definition}

\section{Base model applied to Tribler}

To obtain more insight into the ordered interaction model, consider the following application:

Tribler is an anonymous peer-to-peer file sharing client. In the application of the model,
the set of agents consists of Tribler clients. Each Tribler client is uniquely identifiable,
but a single real world entity could have multiple agents. In Tribler an interaction
consists of two agents uploading data to each other. The amount of work $w_p$ performed
by an agent $p$ is the amount of megabytes uploaded to their peer ($q$), in MB.

In Tribler, these interactions are recorded in a distributed datastructure, called the multichain.
Every client saves and signs their interactions, marked with a sequence number. They will then request
a digital signature from their peer, who will mark the interaction with their own sequence number.
These sequence numbers induce a partial ordering, where $i < j$, if and only if there exists
a sequence $(i_0, i_1, \ldots i_n)$, where $i=i_0, j=i_n$ and every pair $(i_k, i_{k+1})$ has
a common agent, for which the sequence number in $i_k$ is lower than in $i_{k+1}$.
This results in a full order on $I_p$, since in that case $(i, j)$ is a valid sequence if
$i$ occurred before $j$ and both involve agent $p$.



\chapter{Accounting mechanisms and sybil-proofness}

The first reputation system that was introduced in Tribler was BarterCast \cite{meulpolder2009bartercast}.
BarterCast is a system designed to deter what is described as ``lazy freeriders''.
In this paper, Meulpolder et al. suggest that for most practical applications, a reputation system does not
need to account for malicious users, just for lazy users. This assertion is based in the observation
that users classified as ``die-hard freeriders'', people who resort to using non-standard software to
cheat the system, are relatively uncommon in real-world systems. 

BarterCast is built on voluntary reporting. All agents in the system can report to other agents
about their interactions with third parties. These reports contain information about how much data
was exchanged between the two agents. These reports are then used in a max-flow based algorithm.
The graph that is constructed has all agents as nodes. Edges are directed and and the capacity
of an edge from agent $i$ to agent $j$ is equal to the magnitude of all data that $i$ has
uploaded to $j$ in bytes. Using this graph, the subjective reputation of $j$ from the perspective
of $i$ is the result of a monotonous function applied to the difference of the max-flow from $j$ to $i$
minus the max-flow from $i$ to $j$.

BarterCast has various desirable properties. Firstly, agents contributing more resources, or consuming
less resources, have a higher reputation. Secondly, it captures the concept of transitive trust. If agent
$j$ uploads a lot of data to agent $i$, $i$ will consider agents who help $j$ reputable. Thirdly,
it is more resistant to cheaters than systems that are based on agents self-reporting their own uploads and
downloads. Finally, this is a system that does not require the presence of any centrality. 

However, BarterCast also has some flaws. In particular, there is a disincentive for agents to report
interactions in which they had a net negative contribution to the network. Even worse, there is no mechanism
to verify who is lying in the case of conflicting reports. This means there exists a strictly optimal 
reporting strategy: Claiming that you uploaded a lot of data to one or more people, even if that is not
the case. This is a major weakness in the protocol and a solution has been suggested by Seuken and 
Parkes~\cite{seuken2010accounting}. 

In addition to the reporting disincentive, there is a more fundamental problem. Bartercast is built
to transitively propagate uploads to you. In some sense, agents are more trusted if they uploaded
more to you. This is a perfectly valid construction. However, the reverse also holds. If an agent
has downloaded a lot, all agents that downloaded from them are transitively punished. While
this seems philosophical at first, but there is an actual sybil
attack that exploits this property:

\begin{example}[Sybil attack on BarterCast]
     Let $i, j$ be agents. Let $j$ upload 1MB to $i$. Hence, the flow from $j$ to $i$ is 1, the flow
    from $i$ to $j$ is 0. Let $j$ create a sybil, $s_1$ and claim that $s_1$ uploaded 1MB to $j$.
    Now the flow from $i$ to $s_1$ is $0$, the flow from $s_1$ to $i$ is 1. Now $s_1$ asks
    for data from $i$, and $i$ obliges and uploads 1MB. Now the flow between $i$ and the others is
    1 in either direction. Now let $j$ create another sybil $s_2$ and claim it uploaded 1MB to $j$. 
    Now the flow from $i$ to $s_2$ is 0, but the flow from $s_2$ to $i$ is 1. 
    So when $s_2$ asks for data, $i$ is likely to oblige. This process can be repeated for an unbounded
    number of sybils, obtaining an unbounded amount of work from $i$.
\end{example}

\section{Accounting mechanisms and DropEdge}

In this paper, Seuken and Parkes introduce the concept of an accounting mechanism. This formalization gives
a little bit more structure to the problem at hand. It is here that the notions of subjective work graphs
and choice sets are also formalized. Subjective work graphs allow for a framework in which agents
do not have a full view of the network, but only have information about agents that they have interacted
with and their peers. Choice sets provide a mechanism to describe which set of agents are requesting
service from another agent at a fixed point in time. 
This concept is relevant, because the way
Seuken and Parkes suggest to patch the problem with BarterCast is to simply ignore all reports of agents
in the choice set and then compute the BarterCast score from the resultant graph.
This solves a large part of the reporting problem. Since there is no longer a disincentive
to report correctly, the assumption is that agents will cooperate and provide reports.
This mechanism is called ``DropEdge''. Seuken and Parkes show that this mechanism satisfies the property
of being ``misreport-proof''. This property states that if an agent is in the choice set, 
any misreport of this agent will not lead to their own score being increased, or the score of
any other agent in the choice set being decreased.

Furthermore, it has been suggested that DropEdge does not get rid of too much valuable information.
This is supported by theorems bounding the resulting scores and the amount of work in the subjective
work graph after dropping the reports from the choice set members. While these results seem to imply
not too much information is lost, the theorems surrounding this information loss all concern statistical
claims assuming a uniform distirbution over the choice sets. This particular choice of distribution is
defensible, but in real situations the distribution over choice sets will be much less uniform, at least
when monitoring over a period of time. The reason for this is that whenever an agents requests or
stops requesting work, the choice set just changes with this one agent.

\section{Defining accounting mechanisms}

Following this work, Seuken and Parkes \cite{seuken2014sybil} formulated a framework that considers sybil attacks as well. 
A sybil attack is defined as constructing a set of identities and interactions between that set and the sybils real identity.
Benificial sybil attacks are then defined as sybil attacks that increase the sybils score, either their real or one of
their false identities, or decrease the score of another  agent, such that one of the sybils identities
is given priority over other agents. Because of the relevance of the results in this paper, a brief summary
and commentary will be provided below. All definitions are due to Seuken and Parkes~\cite{seuken2014sybil}.

\begin{definition}[Work Graph]
    A work graph $G = (V, E, w)$ has vertices $V = \{1, \ldots, n\}$, one for each agent, and directed
    edges $(i, j) \in E$, for $i, j \in V$, corresponding to work performed by $i$ for $j$, with weight
    $w(i,j) \in \bb{R}_{\geq0}$ denoting the number of units of work.
    \label{def:work_graph}
\end{definition}

The work graph is a model of the objective truth about what happened. However, in a distributed system,
not everyone may have knowledge of all interactions, and there may be disagreement. To this end, agent
information and subjective work are considered.

\begin{definition}[Agent Information]
   Each agent $i \in V$ keeps a private history $(w_i(i,j), w_i(j, i))$ of its interactions with
   other agents $j \in V$, where $w_i(i,j)$ and $w_i(j,i)$ are the work performed for $j$ and
   received from $j$ respectively.
\end{definition}

\begin{definition}[Subjective Work Graph]
   A subjective work graph from agent i's perspective, $G_i = (V_i, E_i, w_i)$, is a set of vertices
   $V_i \subseteq V$ and directed edges $E_i$. Each edge $(j, k) \in E_i$ for which $i \notin \{j, k\}$,
   is labeled with one, or both, of weights $w^j_i(j, k), w_i^k(j, k)$ as known to $i$. For edges $(i,j)$
   and $(j,i)$ the associated weight is $w_i^i(i,j) = w(i,j)$ and $w_i^i(j, i) = w(j,i)$ respectively.
\end{definition}

The definition of a subjective work graph contains a lot of machinery to deal with conflicting information
and already resolves some of the conflicts. In particular, if reports of others conflict with the observations
of the agent itself, those reports are not considered. This model does not assume anything about the truthfulness
of the reports used to constructed the subjective work graph, but it is implied that all information concerning
interactions involving agent $i$ themselves is correct.

\begin{definition}[Choice Set]
    We let $C_i \subseteq V \setminus \{i\}$ denote the choice set for agent $i$, i.e., the set of agents that
    are currently interested in receiving some work from $i$.
    \label{def:choice_set}
\end{definition}

\begin{definition}[Accounting Mechanism]
   An accounting mechanism $M$ takes as input a subjective work graph $G_i$, a choice set $C_i$, and
   determines the score $S_j^M(G_i, C_i) \in \bb{R}$, for any agent $j \in C_i$, as viewed by agent
   $i$.
   \label{def:acc_mech}
\end{definition}

Note that definitions \ref{def:choice_set} and \ref{def:acc_mech} consider highly decentralized mechanisms.
Both are centered around a single agent, who will then compute possibly subjective scores. Because each
agent should be able to do this, accounting mechanisms that are to be deployed in real world systems need
to be efficiently computable. 

\begin{definition}[Allocation Policy]
    Given $G_i$, choice set $C_i$ and an accounting mechanism $M$, an allocation policy $A$
    is a function that maps these to an agent $j \in C_i$. This choice is denoted
    by $A(S^M(G_i, C_i))$. This agent is chosen to recieve a unit of work from $i$.
    \label{def:all_pol}
\end{definition}

Note that in definition \ref{def:all_pol} the term function is to be taken in a flexible sense,
in that this function may include randomization. This definition is also not part of the original work,
where only the following example is given.

\begin{example}[Winner-Take-All]
   The winner-take-all allocation policy (WTA) selects the agent with the highest score,
   breaking any ties randomly:
   \begin{equation*}
       A(S^M(G_i, C_i)) = \arg \max_{k\in C_i} S_k^M(G_i, C_i) 
   \end{equation*}
\end{example}

This is one the simplest allocation policies possible. Other options could involve  
splitting the resources or more randomization.

Definitions \ref{def:work_graph} through \ref{def:all_pol} supply the framework for accounting
mechanisms. Accounting mechanisms are closely related to reputation systems. The difference
between the two lies in that reputation systems are more about trust, whereas accounting mechanisms,
as the name suggests, account something. Often this is work, or service, quantified in some way.
Accounting systems are applicable in cases where we are less concerned with the actual identity
of users, and more concerned with the resource consumption of each agent relative to their contributions.

\subsection{Properties of accounting mechanisms}

Now that the basis for accounting mechanisms has been provided, it is possible to consider different
properties that accounting mechanisms can possess. To start off with, two properties that might have
been included in the definition, but are not quite so generic that one would want to do this.

\begin{property}[Independence of Disconnected Agents (IDA)]
    Let $M$ be an accounting mechanism, let $G_i = (V_i, E_i, w_i)$ be a subjective work graph, let 
    $C_i$ be a choice set. $k \in V_i$ is a disconnected agent, if for this agent there are no edges
    in $E_i$, or for this agent all edges in $E_i$ have zero weight. By $G_i'$ we denote the subjective
    work graph with a disconnected agent $k$ removed.

    $M$ satisfies ``Independence of Disconnected Agents'' if for any disconnected agent $k$, the following
    holds:

    \begin{equation*}
        \forall j \in V_i' : S_{ij}^M(G_i, C_i) = S_{ij}^M(G'_i, C'_i)
    \end{equation*}
    \label{prop:ida}
\end{property}

\begin{property}[Anonimity (ANON)]
    Let $M$ be an accounting mechanism, let $G_i = (V_i, E_i, w_i)$ be a subjective work graph, let 
    $C_i$ be a choice set and let $f$ be a graph isomorphism such that $G'_i = f(G_i)$, $C'_i = f(C_i)$
    and $f(i) = i$. $M$ satisfies anonymity if the following condition holds:

    \begin{equation*}
        \forall j \in V_i \setminus \{i\} : S_{ij}^M(G_i, C_i) = S_{if(j)}^M(G'_i, C'_i)
    \end{equation*}
    \label{prop:anon}
\end{property}

Property \ref{prop:ida} simply states that scores are not affected by adding or removing agents
that are not connected to the rest of the network. On the one hand, this is a fairly reasonable property.
In particular, it provides possible routes for proofs. On the other hand, it is possible to imagine systems
in which this property does not hold. In particular, mechanisms that do assign score to independent agents,
but limit the sum of these scores might not possess this property.

Property \ref{prop:anon} is also a common property of accounting mechanisms. It essentially states that
scores can only be based on the structure of the subjective work graph. If two agents seem exactly the
same with respect to the subjective work graph, they must get the same score. Again, it is possible
to imagine accounting mechanisms without this property, but they will likely need more information
about agents than present in the work graph to assign sensible differing scores.

Seuken and Parkes also consider a property called ``misreport-proofness''. This property
states that no advantage can be obtained by reporting interactions that did not happen,
or wrongly reporting transactions that did. This property is not relevant because
the multichain externalizes this problem. 

\subsection{Defining sybil attacks}

At this point, this work will slightly diverge from the model used by Seuken and Parkes. 
Seuken and Parkes define a sybil attack from a single point. Only one identiy is allowed
to interact with the rest of the network, and all sybil identities can only interact with
each other and the single agent that interacts with the network. This approach is quite
limiting in the sense that it is generally easy for an attacker to interact with the 
real network through several identities. Hence, the definition presented here
includes the ability to perform a sybil attack with multiple identities. This definition
collapses to the one used by Seuken and Parkes if $|J|=1$.

\begin{definition}[Sybil attack]
    Given a subjective work graph $G_i = (V_i, E_i, w_i)$.
    A sybil atttack by agents $J \subseteq V_i$ is a tuple $\sigma_J = (V_s, E_s, w_s)$
    where $V_s = \{ s_{J_1}, s_{J_2}, \ldots\}$ is a set of sybils, 
    $E_s = \{(x, y) : x, y \in S \cup J\}$, and $w_s$ are the edge weights for
    the edges in $E_s$. Applying the sybil attack to agent $i$'s subjective work graph
    is done in the same way as for normal sybil attacks.
    \label{def:collsybil}
\end{definition}

On the face, Definition \ref{def:collsybil} doesn't seem to add much to the definition of a sybil attack.
After all, an attacker can already create an arbitrary amount of identities. However, the definition of a
sybil attack only allows a single point where sybils can interact with the rest network, which is a pretty limited
view of possible attacks. 

\begin{definition}[Sybil attack profit]
    Let $G_i$ be a subjective work graph. For all $j \in \bb{N}$, let $(\sigma_J)_j$ be a sybil attack
    on $(G_i)_j$, where $(G_i)_0 := G_i$ and $(G_i)_j$ for $j > 0$ is defined by the subjective
    work graph that consists of $(G_i)_{j-1}$ and the assignment of one unit of work to 
    $A(S^M( (G_i)_{j-1}, C_i))$.

    Let $\omega^n_-$ be the amount of work that any of the agents in $J$ have performed for
    the network after $n$ steps. Let $\omega^n_+$ be the amount of work that $J$ of any of their
    sybils obtain from the network.

    The profit of this sequence of sybil attacks is:
    \begin{equation*}
        \sup \{\frac{\omega^n_+}{\omega^n_-}\ : n \in \bb{N}, \omega^n_- \neq 0\}
    \end{equation*}

    If this supremum is unbounded, the sybil attack is strongly beneficial.

    If the supremum exists and is strictly larger than 1, the sybil attack is 
    profitably weakly benificial.

    If the supremum exists and is smaller than or equal to 1, the sybil attack
    is unprofitably weakly benificial. This case is also known as ``contributing to the network''.
    \label{def:sybil_profit}
\end{definition}

Definition \ref{def:sybil_profit} provides a certain amount of backwards compatibility with the work
of Seuken and Parkes, while still being more distinctive with respect to the different impacts
sybil attacks can have on the network. In addition, note that the gap between profitably weakly
benificial and strongly beneficial is quite small. In particular, profitibly weakly beneficial
attacks can be repeated by new identities for infinite profit. The difference lies in that
this infinite profit then requires infinte contribution as well.

\section{Bounding sybil attack profit}

The following section describes how an accounting mechanism can be constructed which is partially
resistant to sybil attacks, in the sense that they can be profitably weakly benificial, with bounded
profit.

\begin{definition}[Strict Winner-Takes-All]
   The strict winner-take-all allocation policy (SWTA) selects the agent with the highest score,
   breaking ties randomly. However, the strict winner-take-all will not select any agent
   when all agents have the same score.
    
\end{definition}

\begin{definition}[Net-flow limited contribution]
    The Net-flow limited contribution accounting mechanism $M$ is defined as follows:
    Given a subjective work graph $G_i = (V_i, E_i, w_i)$ and choice set $C_i$, agent
    $i$ computes the the following for each agent $j$: 
    $c_j := \max\{MF_{G_i}(j,i) - MF_{G_i}(i,j), 0\}$.
    Let $G_i^N$ be the graph $G_i$ modified with $c_j$ as node capacities for each node,
    except for $c_i$ which should be unbounded.

    Now $S^M_j(G_i, C_i) = MF_{G_i^N}(j, i)$.
\end{definition}

\begin{theorem}[Properties and robustness of Net-flow]
    Net-flow as accounting mechanism, with SWTA as allocation policy
    satisfies IDA, ANON, weak transitive trust and is robust against
    profitably weakly benificial sybil attacks.

    \label{thm:prop-rob-net-flow}
\end{theorem}

\begin{proof}
    IDA follows from the fact that flow to and from agents does not change if independent agents
    are added or removed. ANON follows from the fact that relabelling nodes will not change the flows.

    Let $k$ be the node added and let 
    $M := \max_{j \in C_i}\{S^M_j(G_i, C_i)\}$ be the largest amount of reputation in the system.
    Then using $W_j = M+1$ and $W_k = M+1$ satisfies the requirements of weak transitive trust.

    Since sybils only have connections to $j$, they cannot be involved in the flow to $j$, hence
    $M$ is resistant to sybil attacks of type $(1)$. For the same reason this scheme is resiliant
    to attack of type (2). For case (3), $s$ can only consume at most the net-flow of $j$ ($c_j$)
    units of work, at which point the net-flow and the reputation of $j$ will be $0$. The net-flow
    is bounded by the contribution of $j$ to the network, so it is impossible to turn a profit of this.
\end{proof}

Note that this result does not contradict those of Seuken and Parkes. The net-flow mechanism is
still vulnerable to weakly-benificial sybil attacks, since those are defined quite widely and
a weakly-benificial sybil attack does not necessarily have to be detrimental to the network,
in particular if a network only cares about work contribution and consumption, and
not about possible other external factors. Furthermore, in contrast to Drop-Edge, net-flow
is choice set independent, which implies there is less computation for varying choice sets.

On the other hand, this algorithm computes two max-flows for every node and then one max-flow for
every nodes that needs to be assigned a score. This means that any algorithm that simply compute
these flows will run for up to $O(n^4)$ time, which is quite harsh. 
Furthermore, this mechanism is quite strict. There is the SWTA policy involved. However,
this is mainly for the benefit of the proof. One could quite easily enable the WTA policy instead.
In this case implication of the theorem is that sybil attack cannot yield a profit, with the exception
of those built on receiving resources by identities with a $0$ score. This is an inconvience,
but not a particularly big problem. 

A much larger problem is the informativeness. In this mechanism,
only peers that have a strict positive contribution in terms of flow will induce network effects.
In existing networks, this subset of the population tends to be fairly small. Hence, a large
number of agents will have a zero score, which means that SWTA would not allocate any resources
to these agents.

\subsection{Improving informativeness by scaling}
An idea to improve the informativeness would be to weight the work performed by the other
agent higher than their work consumed. The idea behind this scheme is that it agents
that perform less work than they consume are tolerated to some degree. This is a trade-off
in the sense that this will allow weakly profitable sybil attacks in exchange for increased
informativeness of the mechanism. In particular, a scaling would need to guarantee
that the leverage the scaling to a strongly profitable sybil attack. 

\begin{definition}[$\alpha$-Net-Flow limited contribution]
    Given a subjective work graph $G_i = (V_i, E_i, w_i)$ and choice set $C_i$, the $\alpha$-scaled
    weights $w_{i,\alpha}$ are defined as follows:

    \begin{equation*}
        w_{i,\alpha}(e) = 
        \begin{cases}
            \frac{w_i(e)}{\alpha} &\mbox{ if } e = (j, i) \mbox{ with } j \in V_i \\
            w_i(e) &\mbox{ otherwise}
        \end{cases}
    \end{equation*}
    
    The $\alpha$-net-flow accounting mechanism is computed as the net-flow accounting
    mechanism, but on the graph $G_i' = (V_i, E_i, w_{i,\alpha})$.

    As a shorthand, this mechanism is denoted by $\alpha$-NF.
\end{definition}

\begin{theorem}[Robustness of $\alpha$-NF]
    $\alpha$-NF with SWTA is robust against weakly benificial sybil attacks with
    profit more than $\alpha$.
    \label{thm:sybil-anf}
\end{theorem}

\begin{proof}
    Since net flow is robust against weakly benificial sybil attacks with profit at most
    1 and the only difference between the two systems is that the contributions of
    agent $i$ are decreased by a factor $\alpha$, it must be the case that the profit
    of a sybil attack can be at most $\alpha$. After all, all altered interactions
    are with $i$ and are therefore known to have actually happened. Therefore, the
    resource consumption of any party can be at most a factor $\alpha$ more than allowed
    by net flow, which implies an upper bound on the sybil attack profit.
\end{proof}

Theorem \ref{thm:sybil-anf} provides an interesting tradeoff. For $\alpha=1$, it reduces
to one of the properties in theorem \ref{thm:prop-rob-net-flow}. For larger $\alpha$,
the mechanism becomes more vulnerable to sybil attacks, but more agents will have
a positive net flow in the first computation step, meaning that more agents will
have a non-zero score, increasing the informativeness of the system. Note
that considering the accounting mechanism on a fixed graph as a function in $\alpha$ to
a vector of scores results in a continuous function. Furthermore, if we let $\alpha$
tend to infinity, this results in an accounting mechanism where every score is the
max-flow from that node to $i$. 

There are more desirable properties of $\alpha$-NF. While on the surface, it seems to
be about ratio's and relative usage, there actually is a subtle way in which
this accounting mechanism cares about absolute amounts of work performed. 
In particular, consider three agents. The first has performed and received
100MB worth of work, the second 70MB and the third 1MB. The second and third
agent have only interacted with the first. If the first computes scores
in 1-NF, then both the second and third agent are assigned a 0 score.
However, in the case of 2-NF, the second agent will have a score of 20MB,
whereas the third will have a score of 0 still. This is because the scaling
of the upload of the first agent could only have an effect on agents which
have downloaded more than the total upload of the first agent, divided
by $\alpha$. 

In a broad sense, this means that choosing a higher $\alpha$ will increase the score 
of agents which have been around longer than yourself, or slightly shorter. This
scheme creates a sort of trickle down system, in which the levels consist of people
who have had a similar total contribution over time. Each level will prioritize
contributing to agents around their level or above it. Any surplus will trickle down
to the lower levels. If a huge influx of users results in an increase in the lower
levels, the higher levels will not be impacted that much, and it will be mainly the
lower levels helping each other.

\chapter{Considering Time}

\subsection{Timeline inference for the base model}

With OIMs, the ordering information of interactions is largely preserved. However, for some
applications it will be useful to be able to associate timestamps with interactions. To
this point, we introduce the concept of timeline inference.

\begin{definition}[Timeline inference for ordered interaction models]
    Let $M = (P, I)$ be an ordered interaction model. 

    $f$ is a \emph{timeline information function} if:
    \begin{itemize}
        \item $J \subseteq I$ 
        \item $f : J \to \bb{R}$
        \item $f$ is increasing with respect to the partial ordering on $I$. That is:
            for $i,j \in J$, if $i \leq j$, then $f(i) \leq f(j)$. 
    \end{itemize}

    By $f[J]$ we denote the range of $f$.
    This allows to define the timeline inference function $T_f$:

    \begin{itemize}
        \item $T_f : I \to f[J] \times f[J]$
        \item $T_f(i) := (\max \{f(j): j \in I, j \leq i\}, \min \{f(j) : j \in I, i \geq j\})$
    \end{itemize}
    
    In addition, we define $\ov{T_f} : I \to \bb{R}$ by $\ov{T_f}(i)$ being the average of the
    two values $T_f(i)$.
\end{definition}


If $f$ represents some sort of temporal information about the interactions in $J$, 
then the timeline inference function gives interval of minimal size containing valid choices for extrapolating
$f$ beyond elements in $J$. In adddition, for every $j \in J$, $T_f(j) = (f(j), f(j))$.

\section{Time-discounted interaction effort}

In order to model the effort needed to interact, we consider the fact that commitment to
a system takes some effort. To this end, we introduce the concept of time-discounted effort.

\begin{definition}[Time-discounted effort]
    Let $M = (P, I)$ be an ordered interaction model, let $f$ be a timeline information function.
    Let $d: \bb{R} \to \bb{R}^+$ be a decreasing function. The time-discounted interaction
    effort is defined as:
    \begin{align*}
        e: & P \times I \to \bb{R} \\
        e(p, i) &= w_p(i)*d(\ov{T_f}(i)) \\
    \end{align*}
\end{definition}

This definition implies that an interaction in the past is regarded as having taken more effort.


In Tribler, timeline information inference can be done by each agent $p$, if they
keep a local record of the time at which they participated in interaction $i$. In this
case the timeline information function will be $f : I_p \to \bb{R}$, where $f(i)$ is
the timestamp of interaction $i$.



\section{The resource distribution problem}

Consider an ordered interaction model $M$. At a specific moment in time, an agent
$p$ has a certain set of other agents suitable for interaction. The problem
at hand is: How should $p$ choose distribute their resources to do work for other agents?


To answer this question, there are several aspects to consider. Firstly, is the issue of
what $p$ intends to achieve. Does $p$ want to distribute their resources in a way that
best helps the collective of all agents? Or maybe he intends to do it such that
he performs work for the people who are most likely to return the favour. Another possibility
is that he wants to compensate others for work they performed for him previously.
Some of these possibilities touch on the game theoretic and sociopsychological angles to this problem.

The second aspect is the availibility of information. In some ordered interaction models, $p$ may
have complete information considering all interactions. In other settings, in particular distributed
systems, it may be expensive or time consuming to obtain all information. It could be that $p$ has only
information concerning their own interactions, or they can just obtain a limited number of transactions.

The third aspect is that there could be additional issues that are not captured in the ordered interaction
model. In particular, the truthfulness of interactions, behavior of agents outside of
events in this framework 




\section{Random walks in the Ordered Interaction Graph}

Random walks have been used in various strategies that combat sybil attacks
in one way or another. In \cite{gkorou2015trust}, random walks are used
in a pure form, more for the purposes of limiting exploration in
a smart way than trying to detect sybils. This paper includes several types
of random walks and considers both the exploratory effect and the
load on important nodes in a random walk.

In \cite{kamvar2003eigentrust}, Kamvar, Schlosser and Garcia-Molina introduce
the EigenTrust algorithm, which is a distributed way to contribute PageRank.
PageRank is the stationary distribution of a random walk \cite{page1999pagerank},
where the random walk is uniform over links, with a probability to jump to a
random node, specified by a distribution on those nodes. The trick in this context
is to distribute the computation over untrusted nodes. 

Yu, Gibbions, Kaminsky and Xiao \cite{yu2008sybillimit} present SybilLimit, which
is a method that is specifically designed for sybil detection. Again, the basis
lies in random walks and this work specifies how to compute the desired
algorithm in a distributed way.








\bibliography{thesis}{}
\bibliographystyle{plain}



\end{document}


